{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case Cientista de Dados - Previsão do Load Factor\n",
        "\n",
        "Esse notebook faz parte do case solicitado pela GOL, para prever o Load Factor das três principais linhas aéreas brasileiras.\n",
        "\n",
        "O projeto, como solicitado, dividido em 2 partes, estas dividas em:\n",
        "- Parte 1\n",
        "  - Criação do Spark Session / Carregamento dos Dados\n",
        "  - Tratamento dos Dados\n",
        "  - Análise Exploratória\n",
        "- Parte 2\n",
        "  - Treino e teste\n",
        "  - Previsão próximos 90 dias\n",
        "  - Previsão com as companhias separadas\n",
        "- Etapa teste\n",
        "  - Cross Validator"
      ],
      "metadata": {
        "id": "JWv66PInM3fx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 1: Criação do Spark Session / Carregamento dos Dados"
      ],
      "metadata": {
        "id": "aeX7MlrR2ofc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Aqui foi criado o ambiente do PySpark.\n",
        "\n",
        "É feita a leitura dos baixados do site da ANAC, do período de 01/01/2023 até 31/07/2025, que foram zipados em um único arquivo.\n",
        "\n",
        "É feita a extração para um único DataFrame Spark, ficando pronto para a etapa de leitura e transformação."
      ],
      "metadata": {
        "id": "ne8DwV-ZO2NU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvvSVH_T2bji"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criando a SparkSession\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sessao_spark = SparkSession\\\n",
        "                    .builder\\\n",
        "                    .appName('Case Cientista de Dados Jr')\\\n",
        "                    .getOrCreate()\n",
        "\n",
        "sessao_spark"
      ],
      "metadata": {
        "id": "q_Dygm_i2tMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extraindo os arquivos zipados\n",
        "\n",
        "zip_name = '/content/basica202.zip'\n",
        "\n",
        "import zipfile, os\n",
        "\n",
        "extract_dir = 'csv_extraidos'\n",
        "\n",
        "with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "os.listdir(extract_dir)\n"
      ],
      "metadata": {
        "id": "pzcph_1C2wJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho da pasta onde estão os arquivos\n",
        "\n",
        "caminho = '/content/csv_extraidos/*.txt'\n",
        "\n",
        "df = sessao_spark.read.csv(\n",
        "    caminho,\n",
        "    sep=';',\n",
        "    header=True,\n",
        "    inferSchema=True,\n",
        "    encoding='latin1'\n",
        ")\n",
        "\n",
        "df.show(5)\n",
        "print('Total de linhas:', df.count())"
      ],
      "metadata": {
        "id": "sI_pqMbr3DE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 1: Tratamento de dados"
      ],
      "metadata": {
        "id": "nMsGOhi63GtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois do carregamento dos dados, é realizada a etapa de tratamento.\n",
        "\n",
        "Foi feita a impressão do schema das colunas, contagem do número de linhas e colunas do DataFrame.\n",
        "\n",
        "\\\n",
        "Depois fora aplicados os filtros solicitados no case:\n",
        "- Companhias aéreas: Azul (AD), GOL (G3) e LATAM (JJ).  \n",
        "- Tipo de grupo: apenas voos REGULAR .  \n",
        "- Natureza da etapa: apenas vôos DOMÉSTICA.\n",
        "\n",
        "\\\n",
        "Foi feita a contagem de valores nulos, com isso, foi feita a remoção da coluna nr_escala_destino, que não tinha nenhum registro, foi feita também a substituição dos valores nulos da coluna nr_chave por 0.\n",
        "\n",
        "\\\n",
        "Foi feita a remoção de serviços tipo CARGUEIRO.\n",
        "\n",
        "\\\n",
        "Depois desses tratamentos, foi iniciada a fase exploratória.\n",
        "\n"
      ],
      "metadata": {
        "id": "n4UnUhcgR0ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import de spark functions\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BAITUZuy3Hd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#schema das colunas\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "leO_5vBQ3KD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quantidade de linhas\n",
        "df.count()"
      ],
      "metadata": {
        "id": "7hM6yjSY3Nl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quantidade de colunas\n",
        "len(df.columns)"
      ],
      "metadata": {
        "id": "XI1bCYMt3Q9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtros de empresa, vôos domésticos e grupo regular\n",
        "\n",
        "df_iata = df.filter(f.col('sg_empresa_iata').isin(['AD','G3','JJ']))\n",
        "df_grupo = df_iata.filter(f.col('ds_grupo_di').isin('REGULAR'))\n",
        "df_filtrado = df_grupo.filter(f.col('ds_natureza_etapa').isin('DOMÉSTICA'))\n",
        "\n",
        "df_filtrado.select('ds_natureza_etapa', 'ds_grupo_di', 'sg_empresa_iata').distinct().show()"
      ],
      "metadata": {
        "id": "bAauenKr3Wgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contagem de valores nulos\n",
        "\n",
        "df_filtrado.select([f.count(f.when(f.isnull(c), 1)).alias(c) for c in df_filtrado.columns]).show()"
      ],
      "metadata": {
        "id": "XkvLGiU63Zfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remoção da coluna nr_escala_destino, que não tem nenhum registro\n",
        "\n",
        "df_filtrado = df_filtrado.drop('nr_escala_destino')\n",
        "df_filtrado.select([f.count(f.when(f.isnull(c), 1)).alias(c) for c in df_filtrado.columns]).show()"
      ],
      "metadata": {
        "id": "8WTthjT63aQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subtituição dos nulo da coluna nr_chave por 0\n",
        "\n",
        "df_fill = df_filtrado.na.fill({'nr_chave': 0})\n",
        "df_fill.select([f.count(f.when(f.isnull(c), 1)).alias(c) for c in df_fill.columns]).show()"
      ],
      "metadata": {
        "id": "dh6tORzh3mT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remoção de serviços do tipo cargueiro\n",
        "\n",
        "df_fill = df_fill.filter(f.col('ds_servico_tipo_linha') != 'CARGUEIRO')\n",
        "df_fill.show(5)"
      ],
      "metadata": {
        "id": "X2a4ikTI3nYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seleciona as colunas e cria a coluna passageiros_totais e load factor raw(1 = 100% vendido)\n",
        "df_metricas = df_fill.select(\n",
        "                        'sg_empresa_iata',\n",
        "                        'dt_partida_real',\n",
        "                        'nr_assentos_ofertados',\n",
        "                        'nr_passag_pagos',\n",
        "                        'nr_passag_gratis',\n",
        "                        'km_distancia',\n",
        "                        'nr_ask',\n",
        "                        'nr_rpk')\\\n",
        "                    .withColumn('total_passageiros', f.col('nr_passag_pagos') + f.col('nr_passag_gratis'))\\\n",
        "                    .withColumn('load_factor_raw',f.when(f.col('nr_ask') > 0, f.col('nr_rpk') / f.col('nr_ask')).otherwise(f.lit(None)))\\\n",
        "                    .withColumn('load_factor_raw',f.when(f.col('load_factor_raw') > 1, 1).otherwise(f.col('load_factor_raw')))\n",
        "\n",
        "\n",
        "df_metricas.show(5)\n",
        "\n",
        "\n",
        "#nr_ask = assentos disponíveis por km voado (A = assentos)\n",
        "\n",
        "#nr_rpk = passageiros por km voado (RP = passageiros)"
      ],
      "metadata": {
        "id": "jqPauVmF8lQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#agregado por dia e por companhia aérea calculando o load factordiário\n",
        "df_diario = df_metricas.filter(f.year(\"dt_partida_real\") != 2022)\\\n",
        "                       .filter(~((f.year(\"dt_partida_real\") == 2025) & (f.month(\"dt_partida_real\") == 8)))\\\n",
        "                       .groupBy('sg_empresa_iata', 'dt_partida_real')\\\n",
        "                       .agg(f.sum('nr_ask').alias('ASK_dia'),\n",
        "                            f.sum('nr_rpk').alias('RPK_dia'),\n",
        "                            f.sum('nr_assentos_ofertados').alias('assentos_ofertados_dia'),\n",
        "                            f.sum('total_passageiros').alias('total_passageiros_dia'),\n",
        "                            f.count('*').alias('qtd_etapas_dia'))\\\n",
        "                       .withColumn('load_factor_dia', f.when(f.col('ASK_dia') > 0, f.col('RPK_dia') / f.col('ASK_dia')).otherwise(f.lit(None)))\\\n",
        "                       .orderBy('dt_partida_real')\n",
        "\n",
        "df_diario.show(10, truncate=False)\n",
        "\n",
        "\n",
        "#nr_ask = assentos disponíveis por km voado (A = assentos)\n",
        "\n",
        "#nr_rpk = passageiros por km voado (RP = passageiros)\n"
      ],
      "metadata": {
        "id": "oxYdn41w-fqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 1: Análise Exploratória"
      ],
      "metadata": {
        "id": "zX8Zj80_HXYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi realizada uma análise para entender o histórico do **Load Factor**(LF) das três principais companhias.\n",
        "\n",
        "\\\n",
        "Foram calculados indicadores básicos por companhia:\n",
        "- Média e mediana do Load Factor diário\n",
        "- Desvio padrão\n",
        "- Valores mínimo e máximo observados\n",
        "- Número de dias com registros válidos\n",
        "\n",
        "Essas métricas ajudam a comparar a dispersão entre as companhias.\n",
        "\n",
        "\\\n",
        "Foi analisada a evolução do **Load Factor** médio mensal para cada companhia.  \n",
        "O gráfico de linha mostra como o LF varia ao longo do tempo:\n",
        "- Tendências de crescimento ou queda\n",
        "- Padrões de alta demanda em determinados meses\n",
        "- Diferenças entre as companhias\n",
        "\n",
        "\\\n",
        "Também foi avaliado o comportamento do LF por dia da semana.  \n",
        "Este mostra quais dias apresentam maior ou menor ocupação, mostrando:\n",
        "- Preferência de passageiros\n",
        "- Possíveis diferenças estratégicas entre as companhias\n",
        "\n",
        "\\\n",
        "Foi construída a distribuição acumulada do LF para cada cia.  \n",
        "Esse gráfico mostra a proporção de dias em que a ocupação foi menor ou igual a determinado valor, permitindo avaliar:\n",
        "- Consistência da ocupação\n",
        "- Frequência de dias com baixo ou alto LF\n",
        "- Comparação entre a estabilidade operacional das companhias\n",
        "\n"
      ],
      "metadata": {
        "id": "K10wJwD0UENu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mostramos a media, mediana, min e max e desvio padrão do load factor por companhia\n",
        "stats = (df_diario.groupBy('sg_empresa_iata')\n",
        "                  .agg(\n",
        "                      f.expr('percentile_approx(load_factor_dia, 0.5)').alias('mediana_LF'),\n",
        "                      f.avg('load_factor_dia').alias('media_LF'),\n",
        "                      f.stddev('load_factor_dia').alias('desvio_LF'),\n",
        "                      f.min('load_factor_dia').alias('min_LF'),\n",
        "                      f.max('load_factor_dia').alias('max_LF'),\n",
        "                      f.count('*').alias('dias_observados'))\n",
        "                 .orderBy('sg_empresa_iata'))\n",
        "\n",
        "stats.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "Ki2Izz9MG3dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cria o df com o load factor medio por Mês para cada uma das 3 companhias\n",
        "df_mes = (df_diario.withColumn('ano_mes', f.date_format('dt_partida_real', 'yyyy-MM'))\n",
        "                   .groupBy('sg_empresa_iata', 'ano_mes')\n",
        "                   .agg(f.avg('load_factor_dia').alias('load_factor_medio'))\n",
        "                   .orderBy('sg_empresa_iata', 'ano_mes'))\n",
        "\n",
        "df_mes.show(31, truncate=False)"
      ],
      "metadata": {
        "id": "JoJKgCGPETAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gráfico de linha mostrando o comportamento do LF ao longo dos meses para cada companhia\n",
        "#itera por cada linha de cada companhia\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_mes = (df_diario.withColumn('ano_mes', f.date_format('dt_partida_real','yyyy-MM'))\n",
        "                   .groupBy('sg_empresa_iata','ano_mes')\n",
        "                   .agg(f.avg('load_factor_dia').alias('lf_medio'))\n",
        "                   .orderBy('sg_empresa_iata','ano_mes')\n",
        "                   .toPandas())\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "for c, l in df_mes.groupby('sg_empresa_iata'):\n",
        "    plt.plot(l['ano_mes'], l['lf_medio'], marker='o', label=c)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Evolução mensal do Load Factor')\n",
        "plt.xlabel('Ano-Mês')\n",
        "plt.ylabel('Load Factor médio')\n",
        "plt.legend(title='Companhia Aérea')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "QcujB--WHZwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cria o df com o load factor medio por dia da semana para cada uma das 3 companhias\n",
        "df_semana = (df_diario.withColumn('dia_semana', f.date_format('dt_partida_real', 'E'))\n",
        "                     .groupBy('sg_empresa_iata', 'dia_semana')\n",
        "                     .agg(f.avg('load_factor_dia').alias('load_factor_medio'),\n",
        "                          f.count('*').alias('qtd_etapas'))\n",
        "                     .orderBy('sg_empresa_iata', 'dia_semana'))\n",
        "\n",
        "df_semana.show(21, truncate=False)\n"
      ],
      "metadata": {
        "id": "3LSnu5jMHgBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostra no gráfico a mesma informação da célula anterior, sendo a Azul a companhia com o menor valor médio de load factor\n",
        "p_df_semana = df_semana.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for c, l in p_df_semana.groupby('sg_empresa_iata'):\n",
        "    plt.plot(l['dia_semana'], l['load_factor_medio'], marker=\"o\", label=c)\n",
        "\n",
        "plt.title('Load Factor médio x dia da semana')\n",
        "plt.xlabel('Dia da semana')\n",
        "plt.ylabel('Load Factor médio')\n",
        "plt.legend(title='Companhia')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ZUzot-h_EHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostra como se distribuem os valores do LF em comparação com a proporção de dias. Dá pra ver quantos 'dias' cada companhia vôou com qual ocupação\n",
        "import numpy as np\n",
        "\n",
        "p_df = df_diario.select('sg_empresa_iata','load_factor_dia').toPandas()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for c, l in p_df.groupby('sg_empresa_iata'):\n",
        "    vals = np.sort(l['load_factor_dia'].dropna())\n",
        "    y = np.arange(1, len(vals)+1) / len(vals)\n",
        "    plt.step(vals, y, label=c)\n",
        "\n",
        "plt.title('Distribuição acumulada do Load Factor')\n",
        "plt.xlabel('Load Factor')\n",
        "plt.ylabel('Proporção acumulada de dias')\n",
        "plt.legend(title='Companhia Aérea')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SiZbNEIeHb16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A análise revelou:\n",
        "\n",
        "\n",
        "   - A Azul (AD) tende a apresentar menores valores médios em comparação à GOL (G3) e LATAM (JJ).\n",
        "   - A GOL e a LATAM mantêm valores mais altos e consistentes, indicando maior eficiência no aproveitamento dos assentos.\n",
        "\n",
        "\n",
        "   - Foi observada sazonalidade, com picos em determinados meses como férias.\n",
        "   - Há tendência de queda em períodos de baixa demanda.\n",
        "\n",
        "   - Aos finais de semana, as companhias podem apresentar variações maiores, possivelmente ligadas ao turismo.\n",
        "\n",
        "   - A Azul (AD) tem maior proporção de dias com Load Factor abaixo de 0.8, mostrando maior volatilidade.\n",
        "   - A GOL (G3) e a LATAM (JJ) concentram boa parte dos dias com Load Factor acima de 0.8, o que mostra maior estabilidade operacional.\n",
        "\n",
        "\\\n",
        " Em resumo:  \n",
        "- **Azul (AD)** → valores médios mais baixos e maior dispersão.  \n",
        "- **GOL (G3)** → boa consistência, ocupação elevada na maior parte dos dias.  \n",
        "- **LATAM (JJ)** → desempenho semelhante à GOL, mas com algumas variações sazonais.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-oBu5ONs4zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 2: Treino e teste"
      ],
      "metadata": {
        "id": "gC-1nRi4M4Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Estratégia adotada**\n",
        "\n",
        "\\\n",
        "Antes de aplicar os modelos, foi realizada a separação do dataset em **treino** e **teste**.  \n",
        "- **Treino**: 70%\n",
        "- **Teste**: 30%\n",
        "- A divisão foi feita de forma aleatória com randomSplit do MLlib.\n",
        "\n",
        "\n",
        "#### Objetivo\n",
        "- Garantir que o modelo aprenda com parte dos dados (treino) e seja validado em dados não vistos (teste).  \n",
        "- As métricas obtidas nessa validação ajudarão na escolha do modelo mais adequado para projetar o Load Factor nos próximos 90 dias.\n",
        "\n"
      ],
      "metadata": {
        "id": "KRbrDlXxvLkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pega a data minima e salva na var, depois cria as colunas de datas(ano, mes, dia...), e por último exibe o resultado do df\n",
        "min_date = df_diario.select(f.date_format(f.min('dt_partida_real'), 'yyyy-MM-dd')).first()\n",
        "min_date_str = min_date[0]\n",
        "\n",
        "df_temporal = df_diario.withColumn('dia_mes', f.dayofmonth('dt_partida_real')) \\\n",
        "                       .withColumn('mes', f.month('dt_partida_real')) \\\n",
        "                       .withColumn('ano', f.year('dt_partida_real')) \\\n",
        "                       .withColumn('dia_semana', f.dayofweek('dt_partida_real')) \\\n",
        "                       .withColumn('dias_inicio', f.datediff('dt_partida_real', f.lit(min_date_str)))\n",
        "\n",
        "df_temporal.select('dt_partida_real',\n",
        "                   'sg_empresa_iata',\n",
        "                   'load_factor_dia',\n",
        "                   'dia_mes',\n",
        "                   'mes',\n",
        "                   'ano',\n",
        "                   'dia_semana',\n",
        "                   'dias_inicio')\\\n",
        "           .show()"
      ],
      "metadata": {
        "id": "d19tcMxmNdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#salva as cols de data numa lista, cria o vetor com o assembles e usa no df\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_cols = ['dia_mes', 'mes', 'ano', 'dia_semana', 'dias_inicio']\n",
        "label_col = 'load_factor_dia'\n",
        "\n",
        "v_assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "df_ml = v_assembler.transform(df_temporal).select('features', label_col)\n",
        "df_ml.show(5, truncate=False)\n"
      ],
      "metadata": {
        "id": "pRGbu3_dPDsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separação de treino e teste\n",
        "train_data, test_data = df_ml.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "print(f'Linhas de treino: {train_data.count()}')\n",
        "print(f'Linhas de teste: {test_data.count()}')\n"
      ],
      "metadata": {
        "id": "NX6mF0UsVoFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**REGRESSÃO LINEAR**\n",
        "\n",
        "**Metodologia**\n",
        "- Modelo simples e interpretável.\n",
        "- Tenta ajustar uma relação linear entre as features e o Load Factor.\n",
        "\n",
        "**Resultados**\n",
        "- A comparação entre valores reais e previstos mostrou que o modelo não conseguiu capturar bem a variabilidade do Load Factor.\n",
        "- Métricas: RMSE alto, R² baixo → indicando baixa efetividade.\n",
        "\n",
        "**Conclusão**\n",
        "- Útil como baseline inicial.\n",
        "- Não adequado para capturar relações não-lineares presentes nos dados.\n",
        "\n"
      ],
      "metadata": {
        "id": "buESdsGBkv9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cria e treina o modelo de regressão linear\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(featuresCol='features', labelCol=label_col)\n",
        "lr_modelo = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "DWPkab3IWU41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#previsão, avaliação com a métrica erro medio e coeficiente de determinação\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "predictions = lr_modelo.transform(test_data)\n",
        "\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=label_col, predictionCol='prediction', metricName='rmse')\n",
        "rmse = evaluator_rmse.evaluate(predictions)\n",
        "print(f'Erro médio (RMSE): {rmse:.4f}')\n",
        "\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=label_col,predictionCol='prediction',metricName='r2')\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "print(f'Coeficiente de Determinação (R²): {r2:.4f}')\n",
        "\n",
        "predictions.select('load_factor_dia', 'prediction').show(10)"
      ],
      "metadata": {
        "id": "y099tzm4X2K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#o gráfico mostra a comparação entre o previsto pelo modelo e o real (só os 100 primeiros vôos), isso mostra que o modelo não está bom e vamos tentar outra abprdagem\n",
        "\n",
        "df_plot = predictions.select('load_factor_dia', 'prediction').toPandas()\n",
        "n = 100\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(df_plot['load_factor_dia'][:n].values, label='Real', marker='o', linestyle='-')\n",
        "plt.plot(df_plot['prediction'][:n].values, label='Previsto',\n",
        "         linestyle='--')\n",
        "plt.title('Load Factor: Real x Previsto (primeiros 100 voos)')\n",
        "plt.xlabel('Vôos')\n",
        "plt.ylabel('Load Factor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IF9-rVdnghkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**RANDOM FOREST**\n",
        "\n",
        "**Metodologia**\n",
        "- Algoritmo baseado em múltiplas árvores de decisão.\n",
        "- Configuração: numTrees=100, maxDepth=5.\n",
        "- Esperava-se capturar melhor padrões não-lineares entre as variáveis.\n",
        "\n",
        "**Resultados**\n",
        "- O modelo melhorou em relação à regressão linear.\n",
        "- Ainda assim, mostrou pouca efetividade em prever corretamente dias com valores extremos de Load Factor.\n",
        "\n",
        "**Conclusão**\n",
        "- Se mostrou mais performático em relação ao baseline.\n",
        "- Funciona bem para dados tabulares, mas ainda limitado para projeções de séries temporais.\n",
        "\n"
      ],
      "metadata": {
        "id": "b147u19lk0Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cria, treina e faz previsão no modelo de floresta\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol='features', labelCol=label_col, numTrees=100, maxDepth=5, seed=42)\n",
        "rf_modelo = rf.fit(train_data)\n",
        "rf_predictions = rf_modelo.transform(test_data)\n"
      ],
      "metadata": {
        "id": "Kv49e3ZFfoIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#avaliação com a métrica erro medio e coeficiente de determinação\n",
        "rmse_rf = evaluator_rmse.evaluate(rf_predictions)\n",
        "print(f'Random Forest - RMSE: {rmse_rf:.4f}')\n",
        "\n",
        "r2_rf = evaluator_r2.evaluate(rf_predictions)\n",
        "print(f'Random Forest - R²: {r2_rf:.4f}')\n"
      ],
      "metadata": {
        "id": "E8suddsEmfcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#o gráfico mostra a comparação entre o previsto pelo modelo e o real (só os 100 primeiros vôos), isso mostra que o modelo não está bom e vamos tentar outra abprdagem\n",
        "df_rf_plot = rf_predictions.select('load_factor_dia', 'prediction').toPandas()\n",
        "\n",
        "n = 100\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(df_rf_plot['load_factor_dia'][:n].values, label='Real', marker='o', linestyle='-')\n",
        "plt.plot(df_rf_plot['prediction'][:n].values, label='Previsto (RF)', linestyle='--')\n",
        "plt.title('Load Factor: Real x Previsto RF (100 primeiros voos)')\n",
        "plt.xlabel('Vôos')\n",
        "plt.ylabel('Load Factor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uxijB2-OnTU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "####**GBTREGRESSOR**\n",
        "\n",
        "**Metodologia**\n",
        "- Constrói árvores de forma sequencial, corrigindo erros das anteriores.\n",
        "- Configuração: maxIter=100, maxDepth=5.\n",
        "- Esperava-se maior precisão em relação à Random Forest.\n",
        "\n",
        "**Resultados**\n",
        "- Apresentou melhor performance entre os modelos testados.\n",
        "- Métricas (RMSE e R²) indicaram melhora significativa em relação à regressão linear.\n",
        "- Capturou mais adequadamente a tendência geral do Load Factor.\n",
        "\n",
        "**Conclusão**\n",
        "- Foi o modelo que apresentou melhor ajuste.\n",
        "- Recomendado para a projeção futura de 90 dias.\n",
        "- Pode ser refinado com ajustes de hiperparâmetros e inclusão de variáveis externas como feriados.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCxPBSAQpZtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cria, treina e faz previsão no modelo de GBTRegressor\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "gbt = GBTRegressor(featuresCol='features',labelCol=label_col, maxIter=100, maxDepth=5, seed=42)\n",
        "gbt_modelo = gbt.fit(train_data)\n",
        "gbt_predictions = gbt_modelo.transform(test_data)\n"
      ],
      "metadata": {
        "id": "K81sQumqnkZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#avaliação com a métrica erro medio e coeficiente de determinação\n",
        "rmse_gbt = evaluator_rmse.evaluate(gbt_predictions)\n",
        "print(f'GBTRegressor - RMSE: {rmse_gbt:.4f}')\n",
        "\n",
        "r2_gbt = evaluator_r2.evaluate(gbt_predictions)\n",
        "print(f'GBTRegressor - R²: {r2_gbt:.4f}')\n"
      ],
      "metadata": {
        "id": "2JBAiV9Yp4tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#o gráfico mostra a comparação entre o previsto pelo modelo e o real (só os 100 primeiros vôos)\n",
        "df_gbt_plot = gbt_predictions.select('load_factor_dia', 'prediction').toPandas()\n",
        "\n",
        "n = 100\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(df_gbt_plot['load_factor_dia'][:n].values, label='Real', marker='o', linestyle='-')\n",
        "plt.plot(df_gbt_plot['prediction'][:n].values, label='Previsto (GBT)', linestyle='--')\n",
        "plt.title('Load Factor: Real x Previsto GBTRegressor (100 primeiros voos)')\n",
        "plt.xlabel('Vôos')\n",
        "plt.ylabel('Load Factor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nAWCF66nqUv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em resumo:\n",
        "- **Regressão Linear** → baseline fraco, não explica bem os dados.  \n",
        "- **Random Forest** → melhora, mas ainda limitado.  \n",
        "- **GBT Regressor** → melhor modelo entre os testados, escolhido para projeções futuras.\n",
        "\n"
      ],
      "metadata": {
        "id": "x2lzGiEkxekx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 2: Previsão próximos 90 dias"
      ],
      "metadata": {
        "id": "BC4j8LhA8SyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Após a etapa de treino e teste, aplicamos o modelo com melhor desempenho **(GBT Regressor)** para gerar previsões do **Load Factor** para os 90 dias subsequentes à última data disponível no dataset.\n",
        "\n",
        "\\\n",
        "**Modelo de predição**\n",
        "- Foi criado um conjunto futuro de datas correspondente ao período de 90 dias à frente.\n",
        "- Essas datas foram transformadas em features pelo VectorAssembler, utilizando a mesma estrutura aplicada nos dados de treino e teste.\n",
        "- O modelo GBT, previamente treinado, foi então aplicado sobre esse conjunto para gerar as previsões.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UGGedaj_2az3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#passa as datas pro pandas, calcula a data min e max, calcula a max + 91 dias, considera domingo como dia 1\n",
        "from datetime import timedelta\n",
        "\n",
        "max_date_str = df_temporal.select(f.date_format(f.max('dt_partida_real'), 'yyyy-MM-dd')).first()[0]\n",
        "max_date = pd.to_datetime(max_date_str)\n",
        "\n",
        "min_date_str = df_temporal.select(f.date_format(f.min('dt_partida_real'), 'yyyy-MM-dd')).first()[0]\n",
        "min_date = pd.to_datetime(min_date_str)\n",
        "\n",
        "future_dates = [max_date + timedelta(days=i) for i in range(1, 90)]\n",
        "\n",
        "df_futuro = pd.DataFrame({'dt_partida_real': future_dates,\n",
        "                          'dia_mes': [d.day for d in future_dates],\n",
        "                          'mes': [d.month for d in future_dates],\n",
        "                          'ano': [d.year for d in future_dates],\n",
        "                          'dia_semana': [d.weekday() + 1 for d in future_dates],\n",
        "                          'dias_inicio': [(d - min_date).days for d in future_dates]})\n",
        "\n",
        "df_futuro.head()\n"
      ],
      "metadata": {
        "id": "OyDlo0Pl8dXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforma novamente o df de pandas para spark\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df_futuro['dt_partida_real'] = df_futuro['dt_partida_real'].astype(str)\n",
        "\n",
        "spark_rows = [Row(**row._asdict()) for row in df_futuro.itertuples(index=False)]\n",
        "df_futuro_spark = sessao_spark.createDataFrame(spark_rows)\n",
        "\n",
        "df_futuro_spark.show(5)\n"
      ],
      "metadata": {
        "id": "TgkSCyRADYY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criacão do modelo\n",
        "df_futuro_features = v_assembler.transform(df_futuro_spark)\n",
        "df_futuro_features.select('dt_partida_real', 'features').show(5, truncate=False)\n"
      ],
      "metadata": {
        "id": "8lEd2_8lFct8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostra a previsão pros proximos 90 dias\n",
        "df_previsoes_futuro = gbt_modelo.transform(df_futuro_features)\n",
        "\n",
        "df_previsoes_futuro.show(5)"
      ],
      "metadata": {
        "id": "bFlsY_6PHUrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_previsoes_futuro.select('dt_partida_real', 'prediction').show(10, truncate=False)"
      ],
      "metadata": {
        "id": "ijWwPmIaSeDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#passa a data pro pandas, ordena, e plota a previsão\n",
        "df_plot_futuro = df_previsoes_futuro.select('dt_partida_real', 'prediction').toPandas()\n",
        "\n",
        "df_plot_futuro['dt_partida_real'] = pd.to_datetime(df_plot_futuro['dt_partida_real'])\n",
        "\n",
        "df_plot_futuro = df_plot_futuro.sort_values('dt_partida_real')\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(df_plot_futuro['dt_partida_real'], df_plot_futuro['prediction'], marker='o', linestyle='-')\n",
        "plt.title('Previsão de Load Factor Próximos 90 dias')\n",
        "plt.xlabel('Data do Voo')\n",
        "plt.ylabel('Load Factor Previsto')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V66g3HuGTome"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resultados\n",
        "- Foi obtida uma série prevista de Load Factor para os próximos 90 dias.\n",
        "- As previsões indicam que:\n",
        "  - Tendências sazonais identificadas na análise exploratória, como variações por dia da semana e por mês foram vistos.\n",
        "  - Os valores médios se mantem dentro do intervalo histórico, o que mostra consistência do modelo.\n",
        "\n",
        "- Os gráficos comparativos mostram a evolução temporal e o comportamento esperado do LF.\n",
        "\n",
        "#### Conclusão\n",
        "- As previsões fornecem uma visão de curto prazo que pode auxiliar a área de Precificação da GOL para criar estratégias de oferta e demanda.\n",
        "- Embora o modelo escolhido (GBT) tenha se mostrado o mais eficaz neste case, melhorias podem ser alcançadas com inclusão de variáveis externas, como feriados.\n"
      ],
      "metadata": {
        "id": "DW306GHB4gPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte 2: Companhias separadas"
      ],
      "metadata": {
        "id": "UsGx96cqV5Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Após a geração da previsão agregada, realizamos a separação por companhia aérea, aplicando o modelo individualmente para cada uma.\n",
        "\n",
        "\\\n",
        "**Metodologia**\n",
        "- Os dados foram divididos por sg_empresa_iata.\n",
        "- Para cada cia, foi criado um conjunto futuro (90 dias a frente).\n",
        "- O modelo foi aplicado a cada conjunto, gerando previsões para cada companhia.\n"
      ],
      "metadata": {
        "id": "HGvJgAfc55Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cria a var cias, dicionario de modelos e lista de resultados\n",
        "cias = ['G3', 'AD', 'JJ']\n",
        "modelos_cia = {}\n",
        "resultados_avaliacao = []"
      ],
      "metadata": {
        "id": "LfL9dGwYWHWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criação do modelo\n",
        "#usa o assembler pra criar a coluna de features, divide os dados de treino e teste e avalia as métricas rmse e r2\n",
        "for c in cias:\n",
        "    print(f'\\nCompanhia: {c}')\n",
        "\n",
        "    df_cia = df_temporal.filter(f.col('sg_empresa_iata') == c)\n",
        "    df_cia_ml = v_assembler.transform(df_cia).select('features', label_col)\n",
        "\n",
        "    train, test = df_cia_ml.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "    modelo = gbt.fit(train)\n",
        "    modelos_cia[c] = modelo\n",
        "\n",
        "    predicoes = modelo.transform(test)\n",
        "\n",
        "    evaluator_rmse = RegressionEvaluator(labelCol=label_col, predictionCol='prediction', metricName='rmse')\n",
        "    rmse = evaluator_rmse.evaluate(predicoes)\n",
        "    evaluator_r2 = RegressionEvaluator(labelCol=label_col, predictionCol='prediction', metricName='r2')\n",
        "    r2 = evaluator_r2.evaluate(predicoes)\n",
        "\n",
        "    resultados_avaliacao.append({\n",
        "        'Companhia': c,\n",
        "        'RMSE': rmse,\n",
        "        'R²': r2})\n",
        "\n",
        "    print(f'RMSE: {rmse:.4f} | R²: {r2:.4f}')\n"
      ],
      "metadata": {
        "id": "FfhJankxXqCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cria o df spark com as datas futuras e a var vazia pra guardar as previsões\n",
        "spark_rows = [Row(**row._asdict()) for row in df_futuro.itertuples(index=False)]\n",
        "df_futuro_spark = sessao_spark.createDataFrame(spark_rows)\n",
        "\n",
        "df_previsoes_cias = None"
      ],
      "metadata": {
        "id": "tBg5rTSNoWlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predição\n",
        "#cria col de cia, cria features, usa o modelo pra gerar previsões e adiciona as previsões na var\n",
        "for c in cias:\n",
        "    print(f'\\nCompanhia: {c}')\n",
        "\n",
        "    df_futuro_cia = df_futuro_spark.withColumn('sg_empresa_iata', f.lit(c))\n",
        "\n",
        "    df_futuro_features = v_assembler.transform(df_futuro_cia)\n",
        "    modelo = modelos_cia[c]\n",
        "    df_previsoes = modelo.transform(df_futuro_features)\n",
        "\n",
        "    df_previsoes_formatado = df_previsoes.select('dt_partida_real', 'sg_empresa_iata', 'prediction')\n",
        "\n",
        "    if df_previsoes_cias is None:\n",
        "        df_previsoes_cias = df_previsoes_formatado\n",
        "    else:\n",
        "        df_previsoes_cias = df_previsoes_cias.union(df_previsoes_formatado)\n",
        "\n",
        "    df_previsoes_cias.orderBy('dt_partida_real', 'sg_empresa_iata').show(5, truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "bqvz9v8ZiX9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot do gráfico de predição para as 3 cias\n",
        "df_previsoes_pd = df_previsoes_cias.toPandas()\n",
        "df_previsoes_pd['dt_partida_real'] = pd.to_datetime(df_previsoes_pd['dt_partida_real'])\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "for c in df_previsoes_pd['sg_empresa_iata'].unique():\n",
        "    df_cia = df_previsoes_pd[df_previsoes_pd['sg_empresa_iata'] == c]\n",
        "    plt.plot(df_cia['dt_partida_real'], df_cia['prediction'], marker='o', label=c)\n",
        "\n",
        "datas = df_previsoes_pd['dt_partida_real'].sort_values().unique()\n",
        "plt.xticks(datas[::15], rotation=45)\n",
        "\n",
        "plt.title('Previsão do Load Factor próximos 90 dias')\n",
        "plt.xlabel('Data do vôo')\n",
        "plt.ylabel('Load Factor previsto')\n",
        "plt.legend(title='Companhia')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LxtrrHbsjk1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Resultados**\n",
        "- **GOL (G3):**\n",
        "  - Apresentou Load Factor alto, mantendo valores próximos à média histórica.\n",
        "  - Mostrou estabilidade e menor dispersão nas previsões.\n",
        "\n",
        "- **Azul (AD):**\n",
        "  - Os valores previstos mostram maior variabilidade.\n",
        "  - Em comparação às outras companhias, a Azul apresentou menores níveis médios de ocupação, conforme já observado na análise exploratória.\n",
        "\n",
        "- **LATAM (JJ):**\n",
        "  - Resultados próximos aos da GOL, mas, com maior oscilação.\n",
        "  - As previsões mostram comportamento que acompanha o padrão histórico.\n",
        "\n",
        "#### **Conclusão**\n",
        "- A análise separada reforça os achados da análise exploratória:\n",
        "  - A **Azul** tende a operar com menor LF médio.\n",
        "  - A **GOL** e a **LATAM** apresentam níveis mais elevados e consistentes de Load Factor.\n",
        "- Essa informação é muito importante para a área de Receitas e Precificação, permitindo a criação de estratégias para o negócio.\n"
      ],
      "metadata": {
        "id": "liI15Q8o62TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa teste: CROSS VALIDATOR\n",
        "\n"
      ],
      "metadata": {
        "id": "O_7r47B9rYE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta etapa foi criada como modelo de treino e teste, com o objetivo de aumentar a acertividade do modelo de previsão, porém, não pode ser testado devido á falta de processamento na hora do .fit do modelo."
      ],
      "metadata": {
        "id": "gSjHNE667tzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #grid de parametros pra testar o cross validator\n",
        "# from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "# param_grid = ParamGridBuilder() \\\n",
        "#     .addGrid(gbt.maxDepth, [3, 5, 7]) \\\n",
        "#     .addGrid(gbt.maxIter, [50, 100]) \\\n",
        "#     .build()\n"
      ],
      "metadata": {
        "id": "k_LnZ7d1q5Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #divide o treino em folds para testar com combinações de parametros diferentes(evaluator rmse)\n",
        "# from pyspark.ml.tuning import CrossValidator\n",
        "\n",
        "# cv = CrossValidator(\n",
        "#     estimator=gbt,\n",
        "#     estimatorParamMaps=param_grid,\n",
        "#     evaluator=evaluator_rmse,\n",
        "#     numFolds=3,\n",
        "#     parallelism=2)"
      ],
      "metadata": {
        "id": "EkzKMP9htLIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #treino do modelo usando o CV\n",
        "# cv_model = cv.fit(train_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "9LgWn2ZXtbqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}